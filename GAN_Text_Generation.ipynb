{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxZDvyI+riZ9nXf/7omFvz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Susrith45/Genie-Gan/blob/main/GAN_Text_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"  # prevents Weights & Biases login prompts\n"
      ],
      "metadata": {
        "id": "ca61VbNe77XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from datasets import Dataset\n"
      ],
      "metadata": {
        "id": "OTEt4rcs8FcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your CSV file in Colab first (my_dataset.csv)\n",
        "df = pd.read_csv(\"my_dataset.csv\")\n",
        "texts = df['text'].tolist()\n",
        "\n",
        "# Preview first 5 sentences\n",
        "print(texts[:5])\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "my_dataset = Dataset.from_dict({\"text\": texts})\n"
      ],
      "metadata": {
        "id": "d7q3_1zI8Ozj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GPT-2 tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# GPT-2 does not have a pad token by default, set it\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Load GPT-2 model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "model.resize_token_embeddings(len(tokenizer))  # adjust vocab size\n"
      ],
      "metadata": {
        "id": "eI206QYO8W2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "tokenized_dataset = my_dataset.map(tokenize_function, batched=True)\n"
      ],
      "metadata": {
        "id": "V2olfxkt8aDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False  # GPT-2 is not masked LM\n",
        ")\n"
      ],
      "metadata": {
        "id": "f6JqsT9h8lQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=2,           # start with 1-2 epochs\n",
        "    per_device_train_batch_size=2,\n",
        "    save_steps=500,\n",
        "    logging_steps=100,\n",
        "    save_total_limit=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIbuJAjz8nuH",
        "outputId": "6c0966e3-3c00-4f2e-fc58-da82bbe4ea08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator\n",
        ")\n"
      ],
      "metadata": {
        "id": "kzsiPy3c8q67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "8E6bhaLZ8str",
        "outputId": "b5e47474-6dda-4d90-f4d0-2bdc095248ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [56/56 04:43, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=56, training_loss=2.843153817313058, metrics={'train_runtime': 296.3021, 'train_samples_per_second': 0.371, 'train_steps_per_second': 0.189, 'total_flos': 7185530880000.0, 'train_loss': 2.843153817313058, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"The acting in this movie\"\n",
        "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "    max_length=60,\n",
        "    num_return_sequences=3,  # generate 3 variations\n",
        "    do_sample=True,\n",
        "    temperature=0.9,\n",
        "    top_k=50,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "for i, sequence in enumerate(output):\n",
        "    print(f\"Generated Review {i+1}:\")\n",
        "    print(tokenizer.decode(sequence, skip_special_tokens=True))\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGuzsbm6-QMw",
        "outputId": "b11012b5-f190-4af0-dd3d-73d929ec4929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Review 1:\n",
            "The acting in this movie was atrocious. I was sick. All characters were weak. Honestly, at times, the performances were disappointing. It was a total disappointment. I liked the movie. I thought the plot was over the top. It was disappointing. The plot didn't work. The acting\n",
            "\n",
            "Generated Review 2:\n",
            "The acting in this movie was horrible. I was hoping for a better movie.\n",
            "\n",
            "4. Overall felt good. This film felt like the movie before. The performance was poor. I enjoyed the ending.\n",
            "\n",
            "7. Storyline was bad. The movie was bad. Was it entertaining?\n",
            "\n",
            "Generated Review 3:\n",
            "The acting in this movie was terrible. There were a lot of jokes and pacing. It was hard to watch after watching the movie. The plot was confusing and over-schedule. The screenplay was poorly executed. The directing was poor. I liked this one.\n",
            "\n",
            "Overall: ★ ★ ★\n",
            "\n"
          ]
        }
      ]
    }
  ]
}